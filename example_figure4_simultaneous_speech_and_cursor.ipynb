{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Figure 4 - Simultaneous speech and cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from matplotlib.patches import Circle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define constants and helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COLORS = [\n",
    "    (0.9254902, 0.12156863, 0.14117647),\n",
    "    (0.98431373, 0.72941176, 0.07058824),\n",
    "    (0.57254902, 0.78431373, 0.24313725),\n",
    "    (0.384, 0.682, 0.2),\n",
    "    (0.43137255, 0.79607843, 0.85490196),\n",
    "    (0.26529412, 0.40686275, 0.72490196),\n",
    "    (0.45568627, 0.31764706, 0.63529412),\n",
    "    (0.84705882, 0.2627451, 0.59215686),\n",
    "]\n",
    "# Lighter versions of the target colors.\n",
    "TRAJECTORY_COLORS = [\n",
    "    (0.9627451, 0.22156863, 0.24117647),\n",
    "    (0.992156865, 0.829411759, 0.17058824),\n",
    "    (0.672549019, 0.88431373, 0.34313725),\n",
    "    (0.45352941, 0.78117647, 0.31058824),\n",
    "    (0.53137255, 0.89607843, 0.927450979),\n",
    "    (0.36529412, 0.52686275, 0.84490196),\n",
    "    (0.55568627, 0.417647059, 0.735294119),\n",
    "    (0.92352941, 0.36274510, 0.69215686),\n",
    "]\n",
    "PROMPTS = [\"bah\", \"though\", \"day\", \"kite\", \"choice\", \"veto\", \"were\"]\n",
    "PROMPT_COLORS = {\n",
    "    \"bah\": (0.71, 0.84, 0.44),\n",
    "    \"though\": (0.75, 0.5, 0.75),\n",
    "    \"day\": (0.88, 0.88, 0.33),\n",
    "    \"kite\": (0.55, 0.81, 0.77),\n",
    "    \"choice\": (0.67, 0.67, 0.67),\n",
    "    \"veto\": (1.0, 0.5, 0.5),\n",
    "    \"were\": (0.9, 0.7, 0.4),\n",
    "}\n",
    "\n",
    "\n",
    "def get_direction_idx_from_vector(vector):\n",
    "    \"\"\"\n",
    "    Given a 2D vector, get an integer from 0 through 7 corresponding to the 1/8th slice\n",
    "    of the unit circle it falls in. Good for identifying a radial8 target, or a position\n",
    "    near a radial8 target.\n",
    "    \"\"\"\n",
    "    x, y = vector\n",
    "\n",
    "    target_angle = np.arctan2(y, x)\n",
    "    if target_angle < 0:\n",
    "        target_angle += 2 * np.pi\n",
    "\n",
    "    direction_idx = int(np.round(target_angle / (np.pi / 4))) % 8\n",
    "\n",
    "    return direction_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the simul task blocks of data from the Simultaneous Speech and Cursor\n",
    "## Session.\n",
    "\n",
    "filepaths = [\n",
    "    \"./dryad_files/t15_day00202_block02_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block03_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block04_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block05_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block06_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block07_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block10_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block11_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block12_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block13_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block14_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block15_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block16_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block17_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block18_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block21_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block22_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block23_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block24_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block25_simultaneous_speech_and_cursor_task.mat\",\n",
    "    \"./dryad_files/t15_day00202_block26_simultaneous_speech_and_cursor_task.mat\",\n",
    "]\n",
    "try:\n",
    "    data = [scipy.io.loadmat(filepath) for filepath in filepaths]\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: Data files not found. Follow steps in the README to download data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate target acquisition times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate target acquisition times and group them by task condition.\n",
    "\n",
    "verbal_blocks_beep_trials = []\n",
    "verbal_blocks_nobeep_trials = []\n",
    "control_blocks_beep_trials = []\n",
    "control_blocks_nobeep_trials = []\n",
    "\n",
    "# The 21 simul blocks (A = verbal, B = control) were collected in 3 sets as follows:\n",
    "# 1. A A B A A B\n",
    "# 2. A A B A A B A A B\n",
    "# 3. A A B A A B\n",
    "# with a break and some cursor calibration before each set.\n",
    "\n",
    "# To allow for a fair comparison between verbal and control blocks, we should have\n",
    "# an A B A structure from each set. Achieve this by excluding the first A in each\n",
    "# set and the last A B in each set.\n",
    "ABA_data = np.concatenate([data[1:4], data[7:13], data[16:19]])\n",
    "\n",
    "for block_data in ABA_data:\n",
    "    timestamps = block_data[\"timestamp_sec\"].flatten()\n",
    "    cursor_go_cue_bins = block_data[\"cursor_go_cue_bin\"].flatten()\n",
    "    speech_go_cue_bins = block_data[\"speech_go_cue_bin\"].flatten()\n",
    "    trial_end_bins = block_data[\"trial_end_bin\"].flatten()\n",
    "    is_control_block = block_data[\"is_control_block\"].item()\n",
    "    is_verbal_block = not is_control_block\n",
    "\n",
    "    for trial_idx in range(len(cursor_go_cue_bins)):\n",
    "        cursor_go_cue_bin = cursor_go_cue_bins[trial_idx]\n",
    "        speech_go_cue_bin = speech_go_cue_bins[trial_idx]\n",
    "        trial_end_bin = trial_end_bins[trial_idx]\n",
    "\n",
    "        # If there was no beep in this trial, the speech go cue bin is -1.\n",
    "        is_beep_trial = speech_go_cue_bin != -1\n",
    "\n",
    "        trial_end_timestamp = timestamps[trial_end_bin]\n",
    "        cursor_go_cue_timestamp = timestamps[cursor_go_cue_bin]\n",
    "        target_acquisition_time = trial_end_timestamp - cursor_go_cue_timestamp\n",
    "\n",
    "        if is_verbal_block:\n",
    "            if is_beep_trial:\n",
    "                verbal_blocks_beep_trials.append(target_acquisition_time)\n",
    "            else:\n",
    "                verbal_blocks_nobeep_trials.append(target_acquisition_time)\n",
    "        else:\n",
    "            if is_beep_trial:\n",
    "                control_blocks_beep_trials.append(target_acquisition_time)\n",
    "            else:\n",
    "                control_blocks_nobeep_trials.append(target_acquisition_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot target acquisition times by condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot a boxplot of trial lengths for each condition.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "condition_trial_times = [\n",
    "    control_blocks_nobeep_trials,\n",
    "    control_blocks_beep_trials,\n",
    "    verbal_blocks_nobeep_trials,\n",
    "    verbal_blocks_beep_trials,\n",
    "]\n",
    "condition_x_positions = [0.5, 1.5, 3.0, 4.0]\n",
    "condition_trial_types = [\n",
    "    \"no beep\\ntrials\",\n",
    "    \"beep\\ntrials\",\n",
    "    \"no beep\\ntrials\",\n",
    "    \"beep\\ntrials\",\n",
    "]\n",
    "condition_colors = [\n",
    "    (0.6, 0.6, 0.9),\n",
    "    (1.0, 0.55, 0.15),\n",
    "    (0.2, 0.27, 0.64),\n",
    "    (1.0, 0.4, 0.0),\n",
    "]\n",
    "\n",
    "boxplot = ax.boxplot(\n",
    "    condition_trial_times,\n",
    "    positions=condition_x_positions,\n",
    "    tick_labels=condition_trial_types,\n",
    "    widths=0.5,\n",
    "    patch_artist=True,\n",
    "    medianprops={\"color\": \"white\", \"linewidth\": 4},\n",
    "    flierprops={\n",
    "        \"markerfacecolor\": (0.5, 0.5, 0.5),\n",
    "        \"markersize\": 6,\n",
    "        \"markeredgecolor\": \"none\",\n",
    "        \"clip_on\": False,\n",
    "    },\n",
    "    capprops={\"linewidth\": 3, \"color\": (0.3, 0.3, 0.3)},\n",
    "    whiskerprops={\"linewidth\": 3, \"color\": (0.3, 0.3, 0.3)},\n",
    ")\n",
    "for box_idx, box in enumerate(boxplot[\"boxes\"]):\n",
    "    box.set_facecolor(condition_colors[box_idx])\n",
    "    box.set_linestyle(\"none\")\n",
    "\n",
    "# Style the plots.\n",
    "\n",
    "ax.set_xlim(-0.25, 4.6)\n",
    "ax.tick_params(axis=\"x\", labelsize=16, length=0, pad=-55)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), weight=\"bold\")\n",
    "for tick_idx, tick in enumerate(ax.get_xticklabels()):\n",
    "    tick.set_color(condition_colors[tick_idx])\n",
    "ax.text(\n",
    "    np.mean(condition_x_positions[:2]),\n",
    "    -0.5,\n",
    "    \"control\\nblocks\",\n",
    "    color=(0.4, 0.4, 0.4),\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "ax.text(\n",
    "    np.mean(condition_x_positions[-2:]),\n",
    "    -0.5,\n",
    "    \"verbal\\nblocks\",\n",
    "    color=(0.1, 0.1, 0.1),\n",
    "    ha=\"center\",\n",
    "    va=\"center\",\n",
    "    fontsize=18,\n",
    "    fontweight=\"bold\",\n",
    ")\n",
    "\n",
    "ax.set_ylim(0, 10)\n",
    "ax.set_yticks(\n",
    "    np.arange(11), labels=[i if i in [0, 5, 10] else \"\" for i in np.arange(11)]\n",
    ")\n",
    "ax.tick_params(axis=\"y\", labelsize=18)\n",
    "ax.set_ylabel(\"target acquisition time (s)\", fontsize=20, labelpad=10)\n",
    "\n",
    "ax.spines[[\"top\", \"right\", \"bottom\"]].set_visible(False)\n",
    "ax.spines[\"left\"].set_linewidth(3)\n",
    "ax.tick_params(axis=\"y\", length=7, width=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial-average aligned to different trial stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trial-average the neural activity, aligned to different stages of the trial.\n",
    "\n",
    "presentation_windows_grouped_by_direction = {\n",
    "    direction_idx: [] for direction_idx in range(8)\n",
    "}\n",
    "cursor_go_cue_windows_grouped_by_direction = {\n",
    "    direction_idx: [] for direction_idx in range(8)\n",
    "}\n",
    "speech_go_cue_windows_grouped_by_prompt = {prompt: [] for prompt in PROMPTS}\n",
    "\n",
    "PRE_GO_CUE_sec = 0.5\n",
    "POST_GO_CUE_sec = 1.0\n",
    "\n",
    "BIN_WIDTH_sec = 0.01\n",
    "PRE_GO_CUE_bins = int(PRE_GO_CUE_sec / BIN_WIDTH_sec)\n",
    "POST_GO_CUE_bins = int(POST_GO_CUE_sec / BIN_WIDTH_sec)\n",
    "\n",
    "for block_data in data:\n",
    "    threshold_crossings = block_data[\"threshold_crossings\"]\n",
    "    target_positions = block_data[\"target_position\"]\n",
    "    target_presentation_bins = block_data[\"target_presentation_bin\"].flatten()\n",
    "    cursor_go_cue_bins = block_data[\"cursor_go_cue_bin\"].flatten()\n",
    "    speech_go_cue_bins = block_data[\"speech_go_cue_bin\"].flatten()\n",
    "    speech_prompts = [s.item() for s in block_data[\"speech_prompt\"].flatten()]\n",
    "    is_control_block = block_data[\"is_control_block\"].item()\n",
    "    is_verbal_block = not is_control_block\n",
    "\n",
    "    # Scale threshold crossings values to represent firing rates in Hz.\n",
    "    firing_rates = threshold_crossings / BIN_WIDTH_sec\n",
    "    # Apply smoothing.\n",
    "    SMOOTHING_SIGMA = 5\n",
    "    firing_rates = gaussian_filter1d(firing_rates, sigma=SMOOTHING_SIGMA, axis=0)\n",
    "\n",
    "    total_bins = len(firing_rates)\n",
    "\n",
    "    ## Windows aligned to target presentation and to cursor go cue.\n",
    "\n",
    "    for trial_idx in range(len(target_presentation_bins)):\n",
    "        target_presentation_bin = target_presentation_bins[trial_idx]\n",
    "        cursor_go_cue_bin = cursor_go_cue_bins[trial_idx]\n",
    "        speech_go_cue_bin = speech_go_cue_bins[trial_idx]\n",
    "\n",
    "        # Skip trials with a beep.\n",
    "        if speech_go_cue_bin != -1:\n",
    "            continue\n",
    "\n",
    "        trial_target = target_positions[target_presentation_bin]\n",
    "\n",
    "        # Skip trials toward the center target (the user can anticipate the target).\n",
    "        CENTER_TARGET = np.array([0.0, 0.0])\n",
    "        is_toward_center_target = np.all(trial_target == CENTER_TARGET)\n",
    "        if is_toward_center_target:\n",
    "            continue\n",
    "\n",
    "        direction_idx = get_direction_idx_from_vector(trial_target)\n",
    "\n",
    "        # Window aligned to target presentation.\n",
    "\n",
    "        presentation_window_start_bin = target_presentation_bin - PRE_GO_CUE_bins\n",
    "        presentation_window_end_bin = target_presentation_bin + POST_GO_CUE_bins\n",
    "\n",
    "        presentation_window = firing_rates[\n",
    "            presentation_window_start_bin:presentation_window_end_bin\n",
    "        ]\n",
    "\n",
    "        presentation_windows_grouped_by_direction[direction_idx].append(\n",
    "            presentation_window\n",
    "        )\n",
    "\n",
    "        # Window aligned to cursor go cue.\n",
    "\n",
    "        cursor_go_cue_window_start_bin = cursor_go_cue_bin - PRE_GO_CUE_bins\n",
    "        cursor_go_cue_window_end_bin = cursor_go_cue_bin + POST_GO_CUE_bins\n",
    "\n",
    "        cursor_go_cue_window = firing_rates[\n",
    "            cursor_go_cue_window_start_bin:cursor_go_cue_window_end_bin\n",
    "        ]\n",
    "\n",
    "        cursor_go_cue_windows_grouped_by_direction[direction_idx].append(\n",
    "            cursor_go_cue_window\n",
    "        )\n",
    "\n",
    "    ## Windows aligned to speech go cue.\n",
    "\n",
    "    for trial_idx in range(len(speech_go_cue_bins)):\n",
    "        speech_go_cue_bin = speech_go_cue_bins[trial_idx]\n",
    "        speech_prompt = speech_prompts[trial_idx]\n",
    "\n",
    "        # Skip trials with no beep.\n",
    "        if speech_go_cue_bin == -1:\n",
    "            continue\n",
    "\n",
    "        # Skip trials in control blocks (since control blocks don't have speech).\n",
    "        if is_control_block:\n",
    "            continue\n",
    "\n",
    "        speech_go_cue_window_start_bin = speech_go_cue_bin - PRE_GO_CUE_bins\n",
    "        speech_go_cue_window_end_bin = speech_go_cue_bin + POST_GO_CUE_bins\n",
    "\n",
    "        # Skip windows at the end of the block which go outside the block.\n",
    "        if speech_go_cue_window_end_bin > total_bins:\n",
    "            continue\n",
    "\n",
    "        speech_go_cue_window = firing_rates[\n",
    "            speech_go_cue_window_start_bin:speech_go_cue_window_end_bin\n",
    "        ]\n",
    "\n",
    "        speech_go_cue_windows_grouped_by_prompt[speech_prompt].append(\n",
    "            speech_go_cue_window\n",
    "        )\n",
    "\n",
    "# Average across trials.\n",
    "presentation_trial_averaged_by_direction = {\n",
    "    direction_idx: np.mean(neural_windows, axis=0)\n",
    "    for direction_idx, neural_windows in presentation_windows_grouped_by_direction.items()\n",
    "}\n",
    "cursor_go_cue_trial_averaged_by_direction = {\n",
    "    direction_idx: np.mean(neural_windows, axis=0)\n",
    "    for direction_idx, neural_windows in cursor_go_cue_windows_grouped_by_direction.items()\n",
    "}\n",
    "speech_go_cue_trial_averaged_by_prompt = {\n",
    "    prompt: np.mean(neural_windows, axis=0)\n",
    "    for prompt, neural_windows in speech_go_cue_windows_grouped_by_prompt.items()\n",
    "}\n",
    "# Get the standard error of the mean.\n",
    "presentation_sem_by_direction = {\n",
    "    direction_idx: np.std(neural_windows, axis=0) / np.sqrt(len(neural_windows))\n",
    "    for direction_idx, neural_windows in presentation_windows_grouped_by_direction.items()\n",
    "}\n",
    "cursor_go_cue_sem_by_direction = {\n",
    "    direction_idx: np.std(neural_windows, axis=0) / np.sqrt(len(neural_windows))\n",
    "    for direction_idx, neural_windows in cursor_go_cue_windows_grouped_by_direction.items()\n",
    "}\n",
    "speech_go_cue_sem_by_direction = {\n",
    "    prompt: np.std(neural_windows, axis=0) / np.sqrt(len(neural_windows))\n",
    "    for prompt, neural_windows in speech_go_cue_windows_grouped_by_prompt.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-averaged firing rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Plot individual channels' trial-averaged firing rates aligned to different stages\n",
    "## of the trial.\n",
    "\n",
    "SELECTED_ELECTRODES = [229, 165, 247]\n",
    "num_bins_in_window = int((PRE_GO_CUE_sec + POST_GO_CUE_sec) / BIN_WIDTH_sec)\n",
    "relative_timestamps = np.linspace(-PRE_GO_CUE_sec, POST_GO_CUE_sec, num_bins_in_window)\n",
    "\n",
    "for electrode_idx in SELECTED_ELECTRODES:\n",
    "    fig, (presentation_ax, cursor_go_cue_ax, speech_go_cue_ax) = plt.subplots(1, 3)\n",
    "\n",
    "    # Plot activity aligned to target presentation.\n",
    "    for direction_idx in range(8):\n",
    "        trial_averaged = presentation_trial_averaged_by_direction[direction_idx][\n",
    "            :, electrode_idx\n",
    "        ]\n",
    "        sem = presentation_sem_by_direction[direction_idx][:, electrode_idx]\n",
    "        color = TARGET_COLORS[direction_idx]\n",
    "        presentation_ax.plot(\n",
    "            relative_timestamps, trial_averaged, color=color, linewidth=2\n",
    "        )\n",
    "        presentation_ax.fill_between(\n",
    "            relative_timestamps,\n",
    "            trial_averaged - sem,\n",
    "            trial_averaged + sem,\n",
    "            color=color,\n",
    "            alpha=0.1,\n",
    "            edgecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        # Add a dot for the target presentation.\n",
    "        presentation_ax.scatter(\n",
    "            [0.0], [-4.0], marker=\"o\", s=95, color=(0.2, 0.2, 0.2), clip_on=False\n",
    "        )\n",
    "        presentation_ax.text(\n",
    "            0.0, -9.0, \"target\\npresentation\", ha=\"center\", va=\"top\", fontsize=16\n",
    "        )\n",
    "\n",
    "        # Add a scale bar for time.\n",
    "        presentation_ax.hlines(\n",
    "            -4.0,\n",
    "            POST_GO_CUE_sec - 0.5,\n",
    "            POST_GO_CUE_sec,\n",
    "            color=(0.2, 0.2, 0.2),\n",
    "            linewidth=3,\n",
    "            clip_on=False,\n",
    "        )\n",
    "        presentation_ax.text(\n",
    "            POST_GO_CUE_sec,\n",
    "            -7.0,\n",
    "            f\"{int(0.5 * 1000)} ms\",\n",
    "            ha=\"right\",\n",
    "            va=\"top\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "\n",
    "        # Style the plot.\n",
    "        presentation_ax.set_xlim(-PRE_GO_CUE_sec, POST_GO_CUE_sec)\n",
    "        presentation_ax.tick_params(bottom=False, labelbottom=False)\n",
    "        presentation_ax.set_ylim(0, 85)\n",
    "        presentation_ax.set_yticks([0, 85])\n",
    "        presentation_ax.tick_params(axis=\"y\", width=3, length=8, labelsize=20)\n",
    "        presentation_ax.set_ylabel(\"firing rate (Hz)\", fontsize=24, labelpad=10)\n",
    "        presentation_ax.spines[\"top\"].set_visible(False)\n",
    "        presentation_ax.spines[\"right\"].set_visible(False)\n",
    "        presentation_ax.spines[\"bottom\"].set_visible(False)\n",
    "        presentation_ax.spines[\"left\"].set_position((\"data\", -PRE_GO_CUE_sec - 0.1))\n",
    "        presentation_ax.spines[\"left\"].set_linewidth(3)\n",
    "\n",
    "    # Plot activity aligned to cursor go cue.\n",
    "    for direction_idx in range(8):\n",
    "        trial_averaged = cursor_go_cue_trial_averaged_by_direction[direction_idx][\n",
    "            :, electrode_idx\n",
    "        ]\n",
    "        sem = cursor_go_cue_sem_by_direction[direction_idx][:, electrode_idx]\n",
    "        color = TARGET_COLORS[direction_idx]\n",
    "        cursor_go_cue_ax.plot(\n",
    "            relative_timestamps, trial_averaged, color=color, linewidth=2\n",
    "        )\n",
    "        cursor_go_cue_ax.fill_between(\n",
    "            relative_timestamps,\n",
    "            trial_averaged - sem,\n",
    "            trial_averaged + sem,\n",
    "            color=color,\n",
    "            alpha=0.1,\n",
    "            edgecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        # Add a dot for the cursor go cue.\n",
    "        cursor_go_cue_ax.scatter(\n",
    "            [0.0], [-4.0], marker=\"o\", s=95, color=(0.2, 0.2, 0.2), clip_on=False\n",
    "        )\n",
    "        cursor_go_cue_ax.text(\n",
    "            0.0, -9.0, \"cursor\\ngo cue\", ha=\"center\", va=\"top\", fontsize=16\n",
    "        )\n",
    "\n",
    "        # Style the plot.\n",
    "        cursor_go_cue_ax.set_xlim(-PRE_GO_CUE_sec, POST_GO_CUE_sec)\n",
    "        cursor_go_cue_ax.set_ylim(0, 85)\n",
    "        cursor_go_cue_ax.tick_params(\n",
    "            left=False, bottom=False, labelleft=False, labelbottom=False\n",
    "        )\n",
    "        cursor_go_cue_ax.spines[\"top\"].set_visible(False)\n",
    "        cursor_go_cue_ax.spines[\"right\"].set_visible(False)\n",
    "        cursor_go_cue_ax.spines[\"bottom\"].set_visible(False)\n",
    "        cursor_go_cue_ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    # Plot activity aligned to speech go cue.\n",
    "    for prompt in PROMPTS:\n",
    "        trial_averaged = speech_go_cue_trial_averaged_by_prompt[prompt][\n",
    "            :, electrode_idx\n",
    "        ]\n",
    "        sem = speech_go_cue_sem_by_direction[prompt][:, electrode_idx]\n",
    "        color = PROMPT_COLORS[prompt]\n",
    "        speech_go_cue_ax.plot(\n",
    "            relative_timestamps, trial_averaged, color=color, linewidth=2\n",
    "        )\n",
    "        speech_go_cue_ax.fill_between(\n",
    "            relative_timestamps,\n",
    "            trial_averaged - sem,\n",
    "            trial_averaged + sem,\n",
    "            color=color,\n",
    "            alpha=0.1,\n",
    "            edgecolor=\"none\",\n",
    "        )\n",
    "\n",
    "        # Add a dot for the speech go cue.\n",
    "        speech_go_cue_ax.scatter(\n",
    "            [0.0], [-4.0], marker=\"o\", s=95, color=(0.2, 0.2, 0.2), clip_on=False\n",
    "        )\n",
    "        speech_go_cue_ax.text(\n",
    "            0.0, -9.0, \"speech\\ngo cue\", ha=\"center\", va=\"top\", fontsize=16\n",
    "        )\n",
    "\n",
    "        # Style the plot.\n",
    "        speech_go_cue_ax.set_xlim(-PRE_GO_CUE_sec, POST_GO_CUE_sec)\n",
    "        speech_go_cue_ax.set_ylim(0, 85)\n",
    "        speech_go_cue_ax.tick_params(\n",
    "            left=False, bottom=False, labelleft=False, labelbottom=False\n",
    "        )\n",
    "        speech_go_cue_ax.spines[\"top\"].set_visible(False)\n",
    "        speech_go_cue_ax.spines[\"right\"].set_visible(False)\n",
    "        speech_go_cue_ax.spines[\"bottom\"].set_visible(False)\n",
    "        speech_go_cue_ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    array_label = data[0][\"array_label_by_electrode\"][electrode_idx].strip()\n",
    "    fig.suptitle(f\"electrode {electrode_idx}\\n(array {array_label})\", fontsize=20)\n",
    "    \n",
    "    fig.set_figwidth(13)\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
